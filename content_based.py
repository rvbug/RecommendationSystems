# -*- coding: utf-8 -*-
"""content-based.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nl8w_FLTohLHtYuMOdjZoTXh3Kjg5934

# Library Imports
"""

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))


import numpy as np # linear algebra
import pandas as pd # data processing
import ast # abstract syntax tree - for processing
import json # processing json
import nltk # for stemming words using PorterStemmer
from nltk.stem.porter import PorterStemmer
from pandas import json_normalize # for normalization
from sklearn.feature_extraction.text import TfidfVectorizer # For vectorizing text
from sklearn.metrics.pairwise import cosine_similarity # to calculate similarity

"""# Load Data"""

credits = pd.read_csv("../input/tmdb-movie-metadata/tmdb_5000_credits.csv")
movies = pd.read_csv("../input/tmdb-movie-metadata/tmdb_5000_movies.csv")

# merging both the data set on ids
df = pd.merge(movies, credits, left_on="id", right_on="movie_id")

"""# Understanding Data"""

# check for top 3 records in the dataframe
df.head(3)

# what is the size of the movie before and after merge
movies.shape, credits.shape, df.shape

# check the datatype
df.info()

"""# Content Based

## Step 1. Select columns

Columns selected

* `id`
* `original_title`
* `overview`
* `genres`
* `keywords`
* `cast`
* `crew`
"""

# select only few columns from the main dataframe
collab_df = df[[ 'id','original_title', 'overview', 'genres', 'keywords',  'cast', 'crew']]
collab_df.head(3)

"""## Step 2. Preprocessing

Convert genres, keywords, cast and crew to a list
"""

collab_df.columns

# sample record
collab_df[collab_df['original_title'] == 'Inception']

# # for testing
# collab_df['original_title'][0:2]
# json.loads(collab_df['genres'][0])
# json.loads(collab_df['keywords'][0])
# json.loads(collab_df['crew'][0])[4:10]

# # for testing
# json.loads(collab_df['cast'][0])[0]
# ast.literal_eval(collab_df['crew'][0])[0]
# ast.literal_eval(collab_df['crew'][0])[0]
# ast.literal_eval(collab_df['crew'][0])[0]

"""## Process all columns"""

# except for crew
def process_dict(obj):
    lst = []
    for i in json.loads(obj):
        lst.append(i['name'])
    return lst

# for crew
def process_crew(obj):
    lst = []
    for i in json.loads(obj):
        if i['job'] == 'Director':
            lst.append(i['name'])
            break
    return lst

collab_df['genres'] = collab_df['genres'].apply(process_dict)
collab_df['keywords'] = collab_df['keywords'].apply(process_dict)
collab_df['cast'] = collab_df['cast'].apply(process_dict)
collab_df['crew'] = collab_df['crew'].apply(process_crew)

collab_df.head(3)

"""## Drop col
Need to drop a column as there are 3 NaNs in overview column.
"""

collab_df.isnull().sum()

# what are those columns
collab_df[collab_df['overview'].isnull()]

# drop those cols
collab_df.dropna(inplace=True)
collab_df.head(3)

# convert overview column to list
collab_df['overview'] = collab_df['overview'].apply(lambda x: x.split())

collab_df.head(3)

"""# Final steps

- Remove spaces on cast and crew names
- Convert to list
- lower case
- stopwords

## Remove Spaces
"""

# There are space like so - we need to remove them to make it unique for all fields
collab_df['cast'][0][0:3]

"""### Convert to list"""

collab_df['overview'] = collab_df['overview'].apply(lambda x: [a.replace(" ", "") for a in x])
collab_df['genres'] = collab_df['genres'].apply(lambda x: [a.replace(" ", "") for a in x])
collab_df['keywords'] = collab_df['keywords'].apply(lambda x: [a.replace(" ", "") for a in x])
collab_df['cast'] = collab_df['cast'].apply(lambda x: [a.replace(" ", "") for a in x])
collab_df['crew'] = collab_df['crew'].apply(lambda x: [a.replace(" ", "") for a in x])

collab_df.head(3)

"""## Combine

Convert the words into their root word for overview, genres and keywords
Then combine them with crew and cast

"""

collab_df['combined'] = collab_df['overview'] + collab_df['genres'] + collab_df['keywords']

"""## Applying Stemming"""

ps = PorterStemmer()

def stemming(text):
    lst = []
    for i in text.split():
        lst.append(ps.stem(i))
    return " ".join(lst)

collab_df['combined'] = collab_df['combined'].apply(lambda x:" ".join(x))
collab_df['combined'] = collab_df['combined'].apply(stemming)

"""## Convert to Strings"""

collab_df['cast'] = collab_df['cast'].apply(lambda x: " ".join(x))
collab_df['crew'] = collab_df['crew'].apply(lambda x: " ".join(x))

collab_df.head(3)

collab_df['combined'][0]

"""## Combine cast, crew with others"""

collab_df['combined'] =  collab_df['combined'] + ' ' + collab_df['cast'] +' '+ collab_df['crew']

collab_df['cast'][0]

collab_df['combined'][10]

collab_df.head(3)

"""# Collaborative Filtering"""

tf = TfidfVectorizer(max_features=5000,analyzer='word',stop_words={'english'})
vectors = tf.fit_transform(collab_df['combined']).toarray()
vectors.shape

"""## What are the top features"""

tf.get_feature_names_out()[:100]

"""## Calculating Cosine Similarity"""

similarity_score = cosine_similarity(vectors)

similarity_score

print("Shape : \n" , similarity_score.shape)
print("\n Sample data: \n",similarity_score[10])
print("\n Single data shape: \n",similarity_score[10].shape)

"""### Sample data
Showing similarity of 10th record with every other movie
"""

similarity_score[10]

"""## Building Recommendations

We will create a function which will take

movie as an argument, find index of the movie and sort it fir

1. Take movie name as the argument
2. Find the index of that movie
3. Sort and enum to get the index
4. Pick the top 5 starting from index 1

"""

def recommend_movies(movie):
    index = collab_df[collab_df['original_title'] == movie].index[0]
    top5 = sorted(list(enumerate(similarity_score[index])), key=lambda x:x[1], reverse=True)[1:6]

    for i in top5:
        print(collab_df.iloc[i[0]].original_title)

recommend_movies('The X Files')

collab_df[collab_df['original_title'].str.contains('The X Files')]

recommend_movies('Batman Begins')

recommend_movies('Bulletproof Monk')

recommend_movies('Die Another Day')

recommend_movies('The Last Airbender')

collab_df['original_title'].sample(10)

collab_df['original_title'].sample(30)

recommend_movies('Spotlight')

recommend_movies('Michael Clayton')

collab_df[collab_df['original_title'].str.contains("Clayton")]

